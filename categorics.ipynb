{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c6ab79",
   "metadata": {},
   "source": [
    "# Winequality dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3878f4",
   "metadata": {},
   "source": [
    "## Feim els imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dc6e88-3d56-48a1-a77e-9cabb57805a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, RidgeCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, SelectKBest, f_regression, RFE\n",
    "from feature_engine.creation import MathematicalCombination, CombineWithReferenceFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10d2f9a",
   "metadata": {},
   "source": [
    "## Preparam el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eabf26f",
   "metadata": {},
   "source": [
    "En aquest apartat, unirem els dos datasets en un, després  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4f7622",
   "metadata": {},
   "source": [
    "Funció que separa les features i les etiquetes, escalant les dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ee3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df):\n",
    "    y=df.quality\n",
    "    X=df.drop('quality',axis=1)\n",
    "    X = min_max_scaler.fit_transform(X)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb9892f",
   "metadata": {},
   "source": [
    "Carregam els datasets a dos dataframes a partir dels fitxers csv: winequality-red.csv i winequality-white.csv\n",
    "\n",
    "Afegim una nova columna que indiqui el tipus de vi a cada dataset i juntam els dos datasets en un de nou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c4b23d-1f27-4596-9b1c-eed4d8cbd32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRed=pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "dfWhite=pd.read_csv(\"winequality-white.csv\", sep=\";\")\n",
    "\n",
    "dfRed['type']=\"Red\"\n",
    "dfWhite['type']=\"White\"\n",
    "df = pd.concat([dfRed,dfWhite])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f6b22c",
   "metadata": {},
   "source": [
    "Consultam les files del dataframe amb valors absents, no fa falta que eliminem cap ja que no n'hi cap amb valors absents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10383ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc5d954",
   "metadata": {},
   "source": [
    "Convertim la columna quality en una columna de valors categòrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae42f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"quality\"]=df[\"quality\"].map(lambda x: 1 if x < 6 else 2 if x == 6 else 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c906be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79bef95",
   "metadata": {},
   "source": [
    "Convertim les característiques categòriques (tipues) en númeriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b734f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = preprocessing.LabelEncoder()\n",
    "\n",
    "df['type']=labelencoder.fit_transform(df['type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba46ec",
   "metadata": {},
   "source": [
    "Recolocam les columnes per tenir la qualitat com a ultima columna. Això no fa falta fer-ho però ho feim per a que els gràfics i altres representacions visuals quedin més entendibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8df7875",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reindex(columns=['fixed acidity', 'volatile acidity', 'citric acid', \n",
    "                       'residual sugar', 'chlorides', 'free sulfur dioxide',\n",
    "                       'total sulfur dioxide', 'density', 'pH', 'sulphates', \n",
    "                       'alcohol', 'type', 'quality'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c976341",
   "metadata": {},
   "source": [
    "Amb el .describe() podrem veure alguns valors estadístics per a cada columna. Com la mitja, la desviació estàndard, els quartils, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b75913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a6a64d",
   "metadata": {},
   "source": [
    "Amb el .info() podem veure quantes files hi ha al dataframe i el seu tipus, com veim totes les columnes consten de valors numérics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca795771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d860288f",
   "metadata": {},
   "source": [
    "## Visualització i neteja de les dades\n",
    "\n",
    "En aquest apartat farem diverses representacións gràfiques de les dades per poder visualitzar-les i decidir si llevam alguna mostra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6760e9ec",
   "metadata": {},
   "source": [
    "Miram quants de vins de cada qualitat hi ha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d7c178",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48e201e",
   "metadata": {},
   "source": [
    "Amb el boxplot podem veure el màxim i mínim no atípic, els quartils, el rang interquartil, la mitja i els outilers de cada caracterísica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710102bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(figsize=(25,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a386933e",
   "metadata": {},
   "source": [
    "Com podem veure tenim molts d'outliers, així que eliminarem els valors que estiguin per devall del percentil 0.5% i per damunt del 99.5%\n",
    "\n",
    "Una altre manera de fer-ho és amb el següent codi que empra una fórmula basada en el rang interquartil, però trobàvem que eliminava massa files.\n",
    "```python\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df = df[~((df[cols] < (Q1 - 1.5 * IQR)) |(df[cols] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85c6f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= ['fixed acidity', 'volatile acidity', 'citric acid', \n",
    "                       'residual sugar', 'chlorides', 'free sulfur dioxide',\n",
    "                       'total sulfur dioxide', 'density', 'pH', 'sulphates', \n",
    "                       'alcohol']\n",
    "\n",
    "Q01=df.quantile(0.005)\n",
    "Q99=df.quantile(0.995)\n",
    "\n",
    "print(\"Forma: \",df.shape)\n",
    "for col in cols:\n",
    "    df = df.drop(df[((df[col] < Q01[col]) | (df[col] > Q99[col]))].index)\n",
    "\n",
    "print(\"Forma de després d'eliminar els outliers: \",df.shape)\n",
    "df.boxplot(figsize=(25,7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5619b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eccc45",
   "metadata": {},
   "source": [
    "Visualitzam les correlacions de les característiques entre elles amb una matriu de correlacions, això ho feim per saber quines característiques estan més o menys relacionades entre si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f322ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "\n",
    "# Generam una màscara pel triangle superior\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Preparam el gràfic de pyplot\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Dibuixam el mapa de calor amb la màscara i alguns paràmetres extra per millorar el resultat visual\n",
    "sns.heatmap(corr, mask=mask, cmap=\"flare\", square=True, linewidths=.25, cbar_kws={\"shrink\": .75})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871b84f2",
   "metadata": {},
   "source": [
    "Graficam el valor que prenen les característiques númeriques del dataframe mitjançant un histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401c3257",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"type\", axis=1).hist(figsize=(10,10), grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a9a3cf",
   "metadata": {},
   "source": [
    "Gràfic cirular en el que podem veure la proporció de vi blanc i vermell del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa060d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(df['type'].value_counts(), labels = [\"White\",\"Red\"], colors=[\"khaki\",\"Maroon\"])\n",
    "print(df['type'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0244528",
   "metadata": {},
   "source": [
    "## Separació del conjunt d'entrenament i el de test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6485ed9",
   "metadata": {},
   "source": [
    "Mesclam el dataframe i carregam les dades a les variables *features* (característiques) i *labels* (etiquetes). \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0244528",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "df = df.sample(frac=1) #No faria faltar mesclar-ho ja que després els classificadors faran un shuffle internament.\n",
    "\n",
    "features, labels = load_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a8121c",
   "metadata": {},
   "source": [
    "Per separar les dades en els conjunts d'entrenament i de test hem emprat la funció train_test_split\n",
    "\n",
    "Hem decidit emprar un 80% entrenament i un 20% de test ja que  amb un valor més baix d'entrenament el model de regressió logistica i el del perceptró presentaven underfiting \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c90c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf550f3",
   "metadata": {},
   "source": [
    "# **Classificadors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ffd632",
   "metadata": {},
   "source": [
    "Per a cada model imprimim el seu classification report, la precisió de training i la de testing. A més, guardam aquests dos valors dins dos dataframes externs per després poder comparar les modificacions que farem al dataframe original.\n",
    "\n",
    "Hem decidit fer els models dins funcions per poder cridar-les des de l'apartat d'[Enginyeria de característiques/Proves](#Proves) fora haver de reescriure el codi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77cb30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrainAccuracy = pd.DataFrame(columns=['Regressió Logística','Perceptró','Random Forest'])\n",
    "dfTestAccuracy = pd.DataFrame(columns=['Regressió Logística','Perceptró','Random Forest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4833d93f",
   "metadata": {},
   "source": [
    "## Regressió Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3641aa45",
   "metadata": {},
   "source": [
    "Hem decidit donar-li valor al hiperparàmetre max_iters perquè amb el valor per defecte no arribava a convergir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4978fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RegressioLogistica(df, nom):\n",
    "    #Carregam les dades del dataframe i cream les variables de Train i Test\n",
    "    features, labels = load_data(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    #Cream una instancia del classificador\n",
    "    logreg = LogisticRegression(max_iter=200)\n",
    "    \n",
    "    #Entrenam el classificador amb les dades de train\n",
    "    logreg.fit(X_train,y_train)\n",
    "    \n",
    "    #Feim una predicció amb les dades de Test\n",
    "    y_predict = logreg.predict(X_test)\n",
    "    \n",
    "    #Imprimim un classification report del test\n",
    "    print(\"\\nRegressio Logística:\")\n",
    "    print(classification_report(y_test, y_predict, zero_division=1))\n",
    "    \n",
    "    #Feim un score amb les dades de train i test per veure l'accuracy dels dos sets de dades\n",
    "    training_accuracy = logreg.score(X_train,y_train)\n",
    "    testing_accuracy = logreg.score(X_test,y_test)\n",
    "    print('training accuracy:', training_accuracy*100)    \n",
    "    print('testing accuracy:', testing_accuracy*100)\n",
    "    \n",
    "    #Afegim les dades a dos dataframes externs per després poder fer comparacions\n",
    "    dfTrainAccuracy.at[nom,'Regressió Logística']=training_accuracy*100\n",
    "    dfTestAccuracy.at[nom,'Regressió Logística']=testing_accuracy*100 \n",
    "    \n",
    "    #Cream una matriu de confusió amb les dades del test\n",
    "    print(\"\\nConfusion Matrix\")\n",
    "    ConfusionMatrixDisplay(confusion_matrix(y_test,y_predict, labels=logreg.classes_), display_labels=logreg.classes_).plot()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "RegressioLogistica(df, \"Original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c53817",
   "metadata": {},
   "source": [
    "## Perceptró"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee48c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perceptro(df, nom):\n",
    "    #Carregam les dades del dataframe i cream les variables de Train i Test\n",
    "    features, labels = load_data(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    #Cream una instancia del classificador\n",
    "    perceptron = Perceptron(max_iter=5000)\n",
    "    \n",
    "    #Entrenam el classificador amb les dades de train\n",
    "    perceptron.fit(X_train,y_train)\n",
    "    \n",
    "    #Feim una predicció amb les dades de Test\n",
    "    y_predict = perceptron.predict(X_test)\n",
    "    \n",
    "    #Imprimim un classification report del test\n",
    "    print(\"\\nPerceptró:\")\n",
    "    print(classification_report(y_test, y_predict, zero_division=1))\n",
    "    \n",
    "    #Feim un score amb les dades de train i test per veure l'accuracy dels dos sets de dades\n",
    "    training_accuracy = perceptron.score(X_train,y_train)\n",
    "    testing_accuracy = perceptron.score(X_test,y_test)\n",
    "    print('training accuracy:', training_accuracy*100)    \n",
    "    print('testing accuracy:', testing_accuracy*100)\n",
    "    \n",
    "    #Afegim les dades a dos dataframes externs per després poder fer comparacions\n",
    "    dfTrainAccuracy.at[nom,'Perceptró']=training_accuracy*100\n",
    "    dfTestAccuracy.at[nom,'Perceptró']=testing_accuracy*100 \n",
    "    \n",
    "    #Cream una matriu de confusió amb les dades del test\n",
    "    print(\"\\nConfusion Matrix\")\n",
    "    ConfusionMatrixDisplay(confusion_matrix(y_test,y_predict, labels=perceptron.classes_), display_labels=perceptron.classes_).plot()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "Perceptro(df, \"Original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b8b61e",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f27cad",
   "metadata": {},
   "source": [
    "Un problema que tenim max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cebbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(df, nom):\n",
    "    #Carregam les dades del dataframe i cream les variables de Train i Test\n",
    "    features, labels = load_data(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    #Cream una instancia del classificador\n",
    "    rf = RandomForestClassifier()\n",
    "    \n",
    "    #Entrenam el classificador amb les dades de train\n",
    "    rf.fit(X_train,y_train)\n",
    "    \n",
    "    #Feim una predicció amb les dades de Test\n",
    "    y_predict = rf.predict(X_test)\n",
    "    \n",
    "    #Imprimim un classification report del test\n",
    "    print(\"\\nRandom Forest:\")\n",
    "    print(classification_report(y_test, y_predict, zero_division=1))\n",
    "    \n",
    "    #Feim un score amb les dades de train i test per veure l'accuracy dels dos sets de dades\n",
    "    training_accuracy = rf.score(X_train,y_train)\n",
    "    testing_accuracy = rf.score(X_test,y_test)\n",
    "    print('training accuracy:', training_accuracy*100)    \n",
    "    print('testing accuracy:', testing_accuracy*100)\n",
    "    \n",
    "    #Afegim les dades a dos dataframes externs per després poder fer comparacions\n",
    "    dfTrainAccuracy.at[nom,'Random Forest']=training_accuracy*100\n",
    "    dfTestAccuracy.at[nom,'Random Forest']=testing_accuracy*100 \n",
    "    \n",
    "    #Cream una matriu de confusió amb les dades del test\n",
    "    print(\"\\nConfusion Matrix\")\n",
    "    ConfusionMatrixDisplay(confusion_matrix(y_test,y_predict, labels=rf.classes_), display_labels=rf.classes_).plot()\n",
    "    \n",
    "    plt.show()\n",
    "           \n",
    "RandomForest(df, \"Original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96654cb7",
   "metadata": {},
   "source": [
    "## Conclusions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c840f50a",
   "metadata": {},
   "source": [
    "El millor model és el Random Forest ja que té una precisió del 69.5% ... COMENTAR UN POC CADA CLASIFICADOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86af37b7",
   "metadata": {},
   "source": [
    "# **Enginyeria de característiques**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb56851",
   "metadata": {},
   "source": [
    "L'enginyeria de característiques (feature engineering) és el procés de selecció, extracció, creació i transformació de les característiques d'un dataset amb l'objectiu de millorar l'eficàcia d'un model predictiu.\n",
    "\n",
    "Per dur a terme l'enginyeria de característiques hem seguit els següents apartats: \n",
    "- **Feature importances dels models**: Ens permet saber la importància de cada característica dins cada model amb el fí d'eliminar les característiques menys importants.\n",
    "- **Correlacions màximes i mínimes**: Ens permet saber quines característiques tenen major correlació entre elles. També ens permet saber quines característiques tenen menys correlació amb la qualitat del vi per després poder eliminar-les.\n",
    "- **Feature Selection**: Selecció de les característiques més i menys importants. S'implementaran els següents:\n",
    "   1. Sequential Feature Selection\n",
    "   2. Univariate Feature Selection amb Kbest\n",
    "   3. Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hem de necessitar un dataframe fora la qualitat, ja que els métodes que empram a continuació ens\n",
    "# creen una máscara de les columnes més o menys importants de longitud columnes-1. \n",
    "# Això és degut a que el nostre dataframe inclou la qualitat però els models s'entrenen fora la qualitat\n",
    "# i per tant tenen una columna menys\n",
    "dfWquality=df.drop(\"quality\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267594fc",
   "metadata": {},
   "source": [
    "## Feature importances de cada model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58731d1c",
   "metadata": {},
   "source": [
    "En aquest apartat emprarem els atributs dels models de classificació desenvolupats anteriorment per elegir les dues característiques amb menys importància"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffe9dfd",
   "metadata": {},
   "source": [
    "### Regressió logística <a id='Regressio-Logistica'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222cce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=5000)\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "logreg_odds = np.exp(logreg.coef_[0])\n",
    "indices=np.argsort(logreg_odds)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Feature importances for Logistic Regression\")\n",
    "ax.barh(range(len(logreg_odds)), logreg_odds[indices])\n",
    "ax.set_yticks(range(len(logreg_odds)))\n",
    "_ = ax.set_yticklabels(np.array(dfWquality.columns)[indices])\n",
    "\n",
    "print(\"Millor característica:\", dfWquality.columns[indices][-1])\n",
    "pitjorLogReg = dfWquality.columns[indices][0]\n",
    "print(\"Pitjor característica\", pitjorLogReg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d8dcd5",
   "metadata": {},
   "source": [
    "### Perceptró <a id='Perceptro'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65baa0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "perceptron_odds = np.exp(perceptron.coef_[0])\n",
    "indices=np.argsort(perceptron_odds)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Feature importances for Perceptron\")\n",
    "ax.barh(range(len(perceptron_odds)), perceptron_odds[indices])\n",
    "ax.set_yticks(range(len(perceptron_odds)))\n",
    "_ = ax.set_yticklabels(np.array(dfWquality.columns)[indices])\n",
    "\n",
    "print(\"Millor característica:\", dfWquality.columns[indices][-1])\n",
    "pitjorPerc =dfWquality.columns[indices][0]\n",
    "print(\"Pitjor característica:\", pitjorPerc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2a8e7f",
   "metadata": {},
   "source": [
    "### Random Forest <a id='Random-Forest'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d4358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "importancesRF = rf.feature_importances_\n",
    "indices = np.argsort(importancesRF)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Feature importances for Random forest\")\n",
    "ax.barh(range(len(importancesRF)), importancesRF[indices])\n",
    "ax.set_yticks(range(len(importancesRF)))\n",
    "_ = ax.set_yticklabels(np.array(dfWquality.columns)[indices])\n",
    "\n",
    "print(\"Millor característica:\", dfWquality.columns[indices][-1])\n",
    "pitjorRF =dfWquality.columns[indices][0]\n",
    "print(\"Pitjor característica:\", pitjorRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fabb9b6",
   "metadata": {},
   "source": [
    "### Comparativa entre models\n",
    "| Model | Millor característica | Pitjor característica |\n",
    "| ----------- | ----------- | ----------- |\n",
    "| Regressió Logística | Volatile Acidity | Alcohol |\n",
    "| Perceptró | Free sulfur dioxide | Sulphates |\n",
    "| Random Forest | Alcohol | Type |\n",
    "\n",
    "Ens pareix curiós que a la regressió logística la pitjor característica sigui l'alcohol però al random forest és la més important.\n",
    "\n",
    "Els resultats poden variar depenent de l'execució, aquests valors són els obtinguts a una execució determinada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7161be23",
   "metadata": {},
   "source": [
    "## Correlacions màximes i mínimes <a id='Correlacions-Minimes'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f48d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = df.corr().abs()\n",
    "s = c.unstack()\n",
    "so = s.sort_values(kind=\"quicksort\", ascending=False)\n",
    "\n",
    "print(\"Majors Correlacions\")\n",
    "print(so[13:23]) #Les 12 primeres son autocorrelacions\n",
    "print(\"-------------\")\n",
    "print(\"Menors correlacions amb qualitat\")\n",
    "print(so['quality'][10:13])\n",
    "pitjorsCorrelacions=so['quality'][10:13].to_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8e52a5",
   "metadata": {},
   "source": [
    "Les característiques que tenen la major correlació amb la qualitat són el *Free sulfur dioxide* i el *Total sulfur dioxide*, així que després provarem d'unir-les \\\n",
    "Les característiques que tenen la menor correlació amb la qualitat són el *pH*, *residual sugars* i *sulphates*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebea7d9",
   "metadata": {},
   "source": [
    "## [Feature Selection](https://www.scikit-learn.org/stable/modules/feature_selection.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8096c",
   "metadata": {},
   "source": [
    "El Feature Selection és un procés de selecció de característiques que ens ajudarà a reduir la quantitat de característiques del model per deixar les més importants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4374fac7",
   "metadata": {},
   "source": [
    "### [Sequential Feature Selector](https://scikit-learn.org/stable/auto_examples/feature_selection/plot_select_from_model_diabetes.html#sphx-glr-auto-examples-feature-selection-plot-select-from-model-diabetes-py) <a id='Sequential-Feature-Selector'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d1cdb4",
   "metadata": {},
   "source": [
    "El Sequential Feature Selector funcia amb dos procediments diferents, el Forward-SFS i el Backward-SFS. \n",
    "\n",
    "El Forward-SFS és un procediment greedy que troba de manera iterativa la millor característica nova per afegir al conjunt de característiques seleccionades. Inicialment començam amb zero característiques i trobam la caracteristica que maximitza una calificació de cross-validation quan un estimador es entrenat amb aquesta característica concreta. Una vegada hem afegit aquesta característica repetim es procés afegint una nova característica al conjunt de característiques seleccionades. El proces acaba quan arriba al nombre de característiques seleccionades desitjat, determinat pel paràmetre n_features_to_select.\n",
    "\n",
    "El Backward-SFS segueix la mateixa idea, però funciona en la direcció oposada: en lloc de començar sense cap característica i afegir-ne, començam amb totes les característiques i eliminam característiques del conjunt. El paràmetre direction controla si s'utilitza el Forward-SFS o el Backward-SFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b757cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.array(dfWquality.columns)\n",
    "ridge = RidgeCV(alphas=np.logspace(-6, 6, num=5)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c0c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_forward = SequentialFeatureSelector(\n",
    "    ridge, n_features_to_select=10, direction=\"forward\"\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "\n",
    "sfs_backward = SequentialFeatureSelector(\n",
    "    ridge, n_features_to_select=10, direction=\"backward\"\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "pitjorSFSF=dfWquality.columns.difference(feature_names[sfs_forward.get_support()]).tolist()\n",
    "pitjorSFSB=dfWquality.columns.difference(feature_names[sfs_backward.get_support()]).tolist()\n",
    "print(type(pitjorSFSB))\n",
    "print(\n",
    "    \"Features selected by forward sequential selection: \"\n",
    "    f\"{feature_names[sfs_forward.get_support()]}\"\n",
    "    \"\\nFeatures not selected by forward sequential selection: \"\n",
    "    f\"{pitjorSFSF}\\n\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Features selected by backward sequential selection: \"\n",
    "    f\"{feature_names[sfs_backward.get_support()]}\"\n",
    "    \"\\nFeatures not selected by forward sequential selection: \"\n",
    "    f\"{pitjorSFSB}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4165dfbc",
   "metadata": {},
   "source": [
    "### [Univariate Feature selection with Kbest](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.GenericUnivariateSelect.html#sklearn.feature_selection.GenericUnivariateSelect) <a id='Univariate-feature-selection'></a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6107a129",
   "metadata": {},
   "source": [
    "El Univariate feature selection funcioan seleccionant les millors característiques basat en proves estadístiques univariades.\n",
    "\n",
    "Nosaltres hem emprat el SelectKBest, que elimina totes les característiques excepte les k millors. No sabem molt bé com funciona internament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b9139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = SelectKBest(f_regression, k=10).fit(X_train, y_train).get_support()\n",
    "\n",
    "best_features = dfWquality.columns[mask].tolist()\n",
    "pitjorsUFS = dfWquality.columns.difference(best_features).tolist()\n",
    "\n",
    "print(\"Millors característiques: \", best_features)\n",
    "print(\"Pitjors característiques: \", pitjorsUFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6c9db6",
   "metadata": {},
   "source": [
    "### [Recursive Feature Elimination](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE) <a id='Recursive-feature-elimination'></a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e286d78a",
   "metadata": {},
   "source": [
    "El Recursive Feature Elimination du a terme una classificació de característiques mitjançant l'eliminació recursiva de característiques.\n",
    "\n",
    "Donat un estimador extern que assigna pesos a les característiques, l'objectiu de l'eliminació de característiques recursives (RFE) és seleccionar característiques considerant recursivament conjunts de característiques cada cop més petits. En primer lloc, l'estimador s'entrena en el conjunt inicial de característiques i la importància de cada característiques s'obté a través de qualsevol atribut . Aleshores, les característiques menys importants s'eliminen del conjunt actual de funcions. Aquest procediment es repeteix recursivament al conjunt podat fins que s'arriba al nombre desitjat de funcions per seleccionar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbcffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.array(dfWquality.columns)\n",
    "ridge = RidgeCV(alphas=np.logspace(-6, 6, num=5)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317b7d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_selector = RFE(ridge, n_features_to_select=10).fit(X_train, y_train)\n",
    "\n",
    "pitjorsRFE=dfWquality.columns.difference(feature_names[rfe_selector.get_support()]).tolist()\n",
    "print(\n",
    "    \"Característiques triades pel recursive feature elimination: \"\n",
    "    f\"{feature_names[rfe_selector.get_support()]}\"\n",
    "    \"\\nCaracterístiques no triades pel recursive feature elimination: \"\n",
    "    f\"{pitjorsRFE}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d2584e",
   "metadata": {},
   "source": [
    "### \n",
    "| Tipus | 1ra Pitjor Caract. | 2na Pitjor Caract.|\n",
    "| ----------- | ----------- | ----------- |\n",
    "| Sequential Feature Selection - Forward| Free sulfur dioxide | Total sulfur dioxide |\n",
    "| Sequential Feature Selection - backward| Chloride | Citric Acid |\n",
    "| Univariate Feature Selection | pH | Sulphates |\n",
    "| Recursive Feature Elimination | Citric Acid | Type |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d142e0",
   "metadata": {},
   "source": [
    "## \n",
    "Una vegada hem fet aquest anàlisi de les dades per arribar a la conclusió de quines eliminar o unir, podem donar lloc al següent pas, on farem modificacions al dataframe original i crearem 3 models per a cada nou dataframe. Una vegada fet això compararem les precisions de tots els models per determinar el model amb major precicisió <a id='Proves'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481dd688",
   "metadata": {},
   "source": [
    "## Eliminam característiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fd782d",
   "metadata": {},
   "source": [
    "En aquest subapartat eliminarem les característiques que, segons els diferents procediments fets anteriorment, tenen menor importància"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfComentaris = pd.DataFrame(columns=['Comentaris'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca265ff",
   "metadata": {},
   "source": [
    "### Característica de menor importància de la Regressió Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd112d94",
   "metadata": {},
   "source": [
    "Com s'ha observat [aquí](#Regressio-Logistica), el Feature Selection de la Regressió Logística indica que és la característica amb menys importància."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06941778",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_menor_LogReg = df.drop(pitjorLogReg,axis=1)\n",
    "\n",
    "RegressioLogistica(df_menor_LogReg, \"menor imp. LogReg\")\n",
    "Perceptro(df_menor_LogReg, \"menor imp. LogReg\")\n",
    "RandomForest(df_menor_LogReg, \"menor imp. LogReg\")\n",
    "\n",
    "dfComentaris.at[\"menor imp. LogReg\",'Comentaris']=pitjorLogReg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392b9511",
   "metadata": {},
   "source": [
    "### Característica de menor importància del Perceptró"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7c3aac",
   "metadata": {},
   "source": [
    "Com s'ha observat [aquí](#Perceptro), el Feature Selection del Perceptró indica que és la característica amb menys importància."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5d0d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_menor_Perc = df.drop(pitjorPerc,axis=1)\n",
    "\n",
    "RegressioLogistica(df_menor_Perc, \"menor imp. Perc\")\n",
    "Perceptro(df_menor_Perc, \"menor imp. Perc\")\n",
    "RandomForest(df_menor_Perc, \"menor imp. Perc\")\n",
    "\n",
    "dfComentaris.at[\"menor imp. Perc\",'Comentaris']=pitjorPerc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2a59bf",
   "metadata": {},
   "source": [
    "### Característica de menor importància del Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd19d2a",
   "metadata": {},
   "source": [
    "Com s'ha observat [aquí](#Random-Forest), el Feature Selection del Random Forest indica que és la característica amb menys importància."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3941ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_menor_RF = df.drop(pitjorRF,axis=1)\n",
    "\n",
    "RegressioLogistica(df_menor_RF, \"menor imp. RF\")\n",
    "Perceptro(df_menor_RF, \"menor imp. RF\")\n",
    "RandomForest(df_menor_RF, \"menor imp. RF\")\n",
    "\n",
    "dfComentaris.at[\"menor imp. RF\",'Comentaris']=pitjorRF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66119db",
   "metadata": {},
   "source": [
    "### Característica amb les pitjors correlacions amb la qualitat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc7d1e9",
   "metadata": {},
   "source": [
    "Com s'ha observat [aquí](#Correlacions-Minimes), són les tres característiques menys correlacionades amb la qualitat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00482efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Correlacions = df.drop(pitjorsCorrelacions,axis=1)\n",
    "\n",
    "RegressioLogistica(df_Correlacions, \"Pitjors carac. Correlacions\")\n",
    "Perceptro(df_Correlacions, \"Pitjors carac. Correlacions\")\n",
    "RandomForest(df_Correlacions, \"Pitjors carac. Correlacions\")\n",
    "\n",
    "dfComentaris.at[\"Pitjors carac. Correlacions\",'Comentaris']=pitjorsCorrelacions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5addbf4c",
   "metadata": {},
   "source": [
    "### Característica amb les pitjors característiques del Forward Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6036be3",
   "metadata": {},
   "source": [
    "Com s'ha observat [aquí](#Sequential-Feature-Selector), ja que el Forward Feature Selection indica que són les dues pitjors característiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc97b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SFSF = df.drop(pitjorSFSF,axis=1)\n",
    "\n",
    "RegressioLogistica(df_SFSF, \"Pitjors carac. SFSF\")\n",
    "Perceptro(df_SFSF, \"Pitjors carac. SFSF\")\n",
    "RandomForest(df_SFSF, \"Pitjors carac. SFSF\")\n",
    "\n",
    "dfComentaris.at[\"Pitjors carac. SFSF\",'Comentaris']=pitjorSFSF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca265ff",
   "metadata": {},
   "source": [
    "### Pitjors característiques Backward Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9006612",
   "metadata": {},
   "source": [
    "Com s'ha observat [aquí](#Sequential-Feature-Selector), el Backward Feature Selection indica que són les dues pitjors característiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06941778",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SFSB = df.drop(pitjorSFSB,axis=1)\n",
    "\n",
    "RegressioLogistica(df_SFSB, \"Pitjors carac. SFSB\")\n",
    "Perceptro(df_SFSB, \"Pitjors carac. SFSB\")\n",
    "RandomForest(df_SFSB, \"Pitjors carac. SFSB\")\n",
    "\n",
    "dfComentaris.at[\"Pitjors carac. SFSB\",'Comentaris']=pitjorSFSB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca265ff",
   "metadata": {},
   "source": [
    "### Pitjors característiques Univariate Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc91033",
   "metadata": {},
   "source": [
    "Com s'ha observat [aquí](#Univariate-feature-selection), el SelectKBest indica que són les dues pitjors característiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06941778",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UFS = df.drop(pitjorsUFS,axis=1)\n",
    "\n",
    "RegressioLogistica(df_UFS, \"Pitjors carac. UFS\")\n",
    "Perceptro(df_UFS, \"Pitjors carac. UFS\")\n",
    "RandomForest(df_UFS, \"Pitjors carac. UFS\")\n",
    "\n",
    "dfComentaris.at[\"Pitjors carac. UFS\",'Comentaris']=pitjorsUFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca265ff",
   "metadata": {},
   "source": [
    "### Pitjors característiques Recursive Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be1e85b",
   "metadata": {},
   "source": [
    "Com hem vist [aquí](#Recursive-feature-elimination), el Recursive Feature Elimination indica que són les dues pitjors característiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06941778",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RFE = df.drop(pitjorsRFE,axis=1)\n",
    "\n",
    "RegressioLogistica(df_RFE, \"Pitjors carac. RFE\")\n",
    "Perceptro(df_RFE, \"Pitjors carac. RFE\")\n",
    "RandomForest(df_RFE, \"Pitjors carac. RFE\")\n",
    "\n",
    "dfComentaris.at[\"Pitjors carac. RFE\",'Comentaris']=pitjorsRFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c15c6",
   "metadata": {},
   "source": [
    "## Cream característiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17d196a",
   "metadata": {},
   "source": [
    "Per crear les característiques noves hem emprat l'eina MathematicalCombinator que ens permet crear noves columnes/variables a partir d'operacions i combinacions d'altres. Per decidir quines característiques creavem o no ens hem basat en la correlació entre característiques i la nostra intuició."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca265ff",
   "metadata": {},
   "source": [
    "### Àcids totals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3057fd",
   "metadata": {},
   "source": [
    "Com tenim l'acidesa fixada i la volàtil, provarem de crear una de nova característica que sigui la total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c244ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-23T12:18:46.123152Z",
     "iopub.status.busy": "2021-01-23T12:18:46.122063Z",
     "iopub.status.idle": "2021-01-23T12:18:46.150621Z",
     "shell.execute_reply": "2021-01-23T12:18:46.151096Z"
    },
    "papermill": {
     "duration": 0.092392,
     "end_time": "2021-01-23T12:18:46.151244",
     "exception": false,
     "start_time": "2021-01-23T12:18:46.058852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combinator_Acid_Tot = MathematicalCombination(\n",
    "    variables_to_combine=['fixed acidity', 'volatile acidity'],\n",
    "    math_operations = ['sum'],\n",
    "    new_variables_names = ['total_acidity']\n",
    ")\n",
    "\n",
    "df_Acid_Tot = combinator_Acid_Tot.fit_transform(df)\n",
    "\n",
    "RegressioLogistica(df_Acid_Tot, \"Acid Totals\")\n",
    "Perceptro(df_Acid_Tot, \"Acid Totals\")\n",
    "RandomForest(df_Acid_Tot, \"Acid Totals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af6e25d",
   "metadata": {},
   "source": [
    "### Percentatge d'àcid cítric respecte de l'acidesa fixada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b200ef19",
   "metadata": {},
   "source": [
    "L'àcid cítric està inclòs dins l'acidesa fixada, així que crearem una nova característica que sigui el percentatge de àcid cítric respecte la fixada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1456e24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinator_PercAC = CombineWithReferenceFeature(\n",
    "    variables_to_combine=['citric acid'],\n",
    "    reference_variables=['fixed acidity'],\n",
    "    operations=['div'],   \n",
    "    new_variables_names=['percentage_citric_acid'])\n",
    "\n",
    "df_PercAC = combinator_PercAC.fit_transform(df)\n",
    "\n",
    "RegressioLogistica(df_PercAC, \"Perc. acid citric\")\n",
    "Perceptro(df_PercAC, \"Perc. acid citric\")\n",
    "RandomForest(df_PercAC, \"Perc. acid citric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca265ff",
   "metadata": {},
   "source": [
    "### Minerals totals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8975c28b",
   "metadata": {},
   "source": [
    "Com tenim els sulfats i els clorurs, que ambdos son minerals cream una nova caraterística anomenada minerals totals que representi la seva suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0bfd90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-23T12:18:46.246874Z",
     "iopub.status.busy": "2021-01-23T12:18:46.243175Z",
     "iopub.status.idle": "2021-01-23T12:18:46.28776Z",
     "shell.execute_reply": "2021-01-23T12:18:46.288288Z"
    },
    "papermill": {
     "duration": 0.094764,
     "end_time": "2021-01-23T12:18:46.288441",
     "exception": false,
     "start_time": "2021-01-23T12:18:46.193677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combinator_Minerals_Totals = MathematicalCombination(\n",
    "    variables_to_combine=['chlorides', 'sulphates'],\n",
    "    math_operations = ['sum'],\n",
    "    new_variables_names = ['total_minerals']\n",
    ")\n",
    "\n",
    "df_Minerals_Totals = combinator_Minerals_Totals.fit_transform(df)\n",
    "\n",
    "RegressioLogistica(df_Minerals_Totals, \"Minerals totals\")\n",
    "Perceptro(df_Minerals_Totals, \"Minerals totals\")\n",
    "RandomForest(df_Minerals_Totals, \"Minerals totals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e5bd8d",
   "metadata": {},
   "source": [
    "### Percentatge de diòxid de sofre lliure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392a16a5",
   "metadata": {},
   "source": [
    "El SO2 lliure i el SO2 total son les dues característiques més relacionades així que cream una nova respecte a aquestes dues que sigui el percentatge de SO2 lliure respecte al total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e667ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-23T12:18:46.377854Z",
     "iopub.status.busy": "2021-01-23T12:18:46.377089Z",
     "iopub.status.idle": "2021-01-23T12:18:46.409562Z",
     "shell.execute_reply": "2021-01-23T12:18:46.408992Z"
    },
    "papermill": {
     "duration": 0.078286,
     "end_time": "2021-01-23T12:18:46.409696",
     "exception": false,
     "start_time": "2021-01-23T12:18:46.33141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combinator_PercSO2 = CombineWithReferenceFeature(\n",
    "    variables_to_combine=['free sulfur dioxide'],\n",
    "    reference_variables=['total sulfur dioxide'],\n",
    "    operations=['div'],   \n",
    "    new_variables_names=['percentage_free_sulfur'])\n",
    "\n",
    "df_PercSO2 = combinator_PercSO2.fit_transform(df)\n",
    "\n",
    "RegressioLogistica(df_PercSO2, \"Perc. SO2 lliure\")\n",
    "Perceptro(df_PercSO2, \"Perc. SO2 lliure\")\n",
    "RandomForest(df_PercSO2, \"Perc. SO2 lliure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da68c40f",
   "metadata": {},
   "source": [
    "### Diòxid de sofre no lliure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2b1f0f",
   "metadata": {},
   "source": [
    "Parescut a l'anterior apartat, aquí cream una nova característica que és el SO2 no lliure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec296257",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinator_No_FreeSO2 = CombineWithReferenceFeature(\n",
    "    variables_to_combine=['total sulfur dioxide'],\n",
    "    reference_variables=['free sulfur dioxide'],\n",
    "    operations=['sub'],\n",
    "    new_variables_names=['non_free_sulfur_dioxide']\n",
    ")\n",
    "\n",
    "df_No_FreeSO2 = combinator_No_FreeSO2.fit_transform(df)\n",
    "\n",
    "RegressioLogistica(df_No_FreeSO2, \"S02 no lliure\")\n",
    "Perceptro(df_No_FreeSO2, \"S02 no lliure\")\n",
    "RandomForest(df_No_FreeSO2, \"S02 no lliure\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f07039",
   "metadata": {},
   "source": [
    "### Unim totes les creacions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66055cc",
   "metadata": {},
   "source": [
    "Juntarem totes les característiques creades en un sol dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d48fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Unió = combinator_Acid_Tot.fit_transform(df)\n",
    "df_Unió = combinator_Minerals_Totals.fit_transform(df_Unió)\n",
    "df_Unió = combinator_PercAC.fit_transform(df_Unió)\n",
    "df_Unió = combinator_No_FreeSO2.fit_transform(df_Unió)\n",
    "df_Unió = combinator_PercSO2.fit_transform(df_Unió)\n",
    "\n",
    "RegressioLogistica(df_Unió, \"Totes creacions\")\n",
    "Perceptro(df_Unió, \"Totes creacions\")\n",
    "RandomForest(df_Unió, \"Totes creacions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6b55b3",
   "metadata": {},
   "source": [
    "## Comparam les precisions i conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f12d46d",
   "metadata": {},
   "source": [
    "En aquest apartat feim un print de les \"accuracies\" de tots les versions del dataframes per poder comparar-les. També calcularem la diferència de cada variació amb l'original i la difern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc05c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training accuracy for each model and each dataframe\\n\", dfTrainAccuracy)\n",
    "print(\"\\nTesting accuracy for each model and each dataframe\\n\", dfTestAccuracy)\n",
    "print(\"\\n\\nLes features eliminades han sigut:\\n\", dfComentaris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32381607",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDiffs = pd.DataFrame(columns=['Regressió Logística','Perceptró','Random Forest'])\n",
    "for index, row in dfTestAccuracy.iterrows():\n",
    "    dfDiffs.at[row.name]=row-dfTestAccuracy.loc['Original']\n",
    "dfDiffs['Media'] = dfDiffs.mean(axis=1)\n",
    "print(dfDiffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbc71db",
   "metadata": {},
   "source": [
    "Com podem veure, les precisions dels models no han millorat gaire després d'aplicar els diferents processos de l'enginenyeria de característiques. Fins i tot n'hi ha colcunes que han empitjorat. \n",
    "\n",
    "Entre totes la que ha tengut una major millora és el dataframe: XXXX en el que hem afegit/eliminat XXXX columna. Això pot ser degut a XXXX ja que XXXX. Cal tenir en compte que els resultats poden variari d'una execució a una altre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b554cb79",
   "metadata": {},
   "source": [
    "# **Grid Search CV**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7d0577",
   "metadata": {},
   "source": [
    "El Grid Search és una tècnica que ens permet determinar els valors òptims dels hiperparàmetres d'un model. L'emprarem per poder millorar els nostres models. \n",
    "\n",
    "_(No acabam de saber que fan exactament tots els hyperparàmetres dels models, així que hem escollit un parell de cada model fora saber ben bé que fan)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4aab54",
   "metadata": {},
   "source": [
    "Farem feina amb el grid search damunt el dataframe: XXXX ja que com hem vist abans tenia la millor accuracy. No cream un conjunt de dades de validació ja que el grid search ho fa internament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08a1584",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = load_data(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c6c9a",
   "metadata": {},
   "source": [
    "## Regressió Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d1c047",
   "metadata": {},
   "source": [
    "Per al grid search de la regressió lógistica mirarem els següents paràmetres:\n",
    "- **Penalty**: Penalització per augmentar la magnitud dels valors dels paràmetres per reduir l'overfitting\n",
    "    - 'l2': Penalització l2\n",
    "    - 'l1': Penalització l1\n",
    "- **C**: Inversa de la força de regularització\n",
    "- **max_iter**: Nombre màxim d'iteracions que triga el solucionador en convergir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdbf758",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={\n",
    "    \"C\":np.logspace(-3,3,7),\n",
    "    \"penalty\":[\"l1\",\"l2\"],\n",
    "    \"max_iter\":[75,100,200,300]}\n",
    "\n",
    "# Create a based model\n",
    "logreg = LogisticRegression()\n",
    "# Instantiate the grid search model\n",
    "grid_search_logreg = GridSearchCV(estimator = logreg, param_grid = param_grid, cv = 10, n_jobs=-1)\n",
    "grid_search_logreg.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search_logreg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe658cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_predict=logreg.predict(X_test)\n",
    "\n",
    "print(\"\\nLogistic Regression:\")\n",
    "print(classification_report(y_test, y_predict,zero_division=1))\n",
    "\n",
    "training_accuracy = logreg.score(X_train,y_train)\n",
    "testing_accuracy = logreg.score(X_test,y_test)\n",
    "\n",
    "print('training accuracy:', training_accuracy*100)    \n",
    "print('testing accuracy:', testing_accuracy*100)\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test,y_predict, labels=logreg.classes_), display_labels=logreg.classes_).plot()  \n",
    "plt.show()\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "logregTunnedParams = logreg.set_params(**grid_search_logreg.best_params_)\n",
    "logregTunnedParams.fit(X_train, y_train)\n",
    "\n",
    "y_predict=logregTunnedParams.predict(X_test)\n",
    "\n",
    "print(\"\\nLogistic Regression:\")\n",
    "print(classification_report(y_test, y_predict,zero_division=1))\n",
    "\n",
    "training_accuracy = logregTunnedParams.score(X_train,y_train)\n",
    "testing_accuracy = logregTunnedParams.score(X_test,y_test)\n",
    "\n",
    "print('training accuracy:', training_accuracy*100)    \n",
    "print('testing accuracy:', testing_accuracy*100)\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test,y_predict, labels=logregTunnedParams.classes_), display_labels=logregTunnedParams.classes_).plot()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1550e955",
   "metadata": {},
   "source": [
    "## Perceptró"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea3189",
   "metadata": {},
   "source": [
    "Per al grid search de la regressió lógistica mirarem els següents paràmetres:\n",
    "- **Penalty**: Penalització per augmentar la magnitud dels valors dels paràmetres per reduir l'overfitting\n",
    "    - 'l2': Penalització l2\n",
    "    - 'l1': Penalització l1\n",
    "- **Alpha**: Constant que multiplica el terme de regularització, si s'empra la regularització\n",
    "- **max_iter**: Nombre màxim d'iteracions que triga el solucionador en convergir\n",
    "- **early_stopping**: Si està establit a True atura l'entrenament quan el validation score deixa de millorar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93dc1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l2', 'l1', 'elasticnet', None],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'max_iter': [75,100,1000,2500,5000],\n",
    "    'early_stopping': [True, False],\n",
    "}\n",
    "# Create a based model\n",
    "perceptro = Perceptron()\n",
    "# Instantiate the grid search model\n",
    "grid_search_Perc = GridSearchCV(estimator = perceptro, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search_Perc.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search_Perc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6157791",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = Perceptron()\n",
    "perc.fit(X_train, y_train)\n",
    "\n",
    "y_predict=perc.predict(X_test)\n",
    "\n",
    "print(\"PERCEPTRON ABANS DEL GRID SEARCH:\")\n",
    "print(classification_report(y_test, y_predict,zero_division=1))\n",
    "\n",
    "training_accuracy = perc.score(X_train,y_train)\n",
    "testing_accuracy = perc.score(X_test,y_test)\n",
    "\n",
    "print('training accuracy:', training_accuracy*100)    \n",
    "print('testing accuracy:', testing_accuracy*100)\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test,y_predict, labels=perc.classes_), display_labels=perc.classes_).plot()  \n",
    "plt.show()\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "percTunnedParams = perc.set_params(**grid_search_Perc.best_params_)\n",
    "percTunnedParams.fit(X_train, y_train)\n",
    "\n",
    "y_predict=percTunnedParams.predict(X_test)\n",
    "\n",
    "print(\"PERCEPTRON DESPRÉS DEL GRIDSEARCH:\")\n",
    "print(classification_report(y_test, y_predict,zero_division=1))\n",
    "\n",
    "training_accuracy = percTunnedParams.score(X_train,y_train)\n",
    "testing_accuracy = percTunnedParams.score(X_test,y_test)\n",
    "\n",
    "print('training accuracy:', training_accuracy*100)    \n",
    "print('testing accuracy:', testing_accuracy*100)\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test,y_predict, labels=percTunnedParams.classes_), display_labels=percTunnedParams.classes_).plot()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceee602e",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37467516",
   "metadata": {},
   "source": [
    "Per al grid search del random forest mirarem els següents paràmetres:\n",
    "- **max_depth**: Màxima profunditat d'un arbre\n",
    "- **max_features**: Nombre de característiques a considerar quan cercam la millor divisió\n",
    "    - 'auto': max_features=sqrt(n_features).\n",
    "    - 'log2': max_features=log2(n_features).\n",
    "    - 'None': max_features=n_features\n",
    "- **n_estimators**: Nombre d'arbres en el bosc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c68f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={\n",
    "    \"n_estimators\":list(range(10,101,10)),\n",
    "    \"max_features\":['auto','log2',None],\n",
    "    \"max_depth\":[15,20,25]\n",
    "    }\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search_rf = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 10, n_jobs = -1)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search_rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d682293",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_predict=rf.predict(X_test)\n",
    "\n",
    "print(\"\\nRANDOM FOREST ABANS DEL GREEDSEARCH:\")\n",
    "print(classification_report(y_test, y_predict,zero_division=1))\n",
    "\n",
    "training_accuracy = rf.score(X_train,y_train)\n",
    "testing_accuracy = rf.score(X_test,y_test)\n",
    "\n",
    "print('training accuracy:', training_accuracy*100)    \n",
    "print('testing accuracy:', testing_accuracy*100)\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test,y_predict, labels=rf.classes_), display_labels=rf.classes_).plot()  \n",
    "plt.show()\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "rfTunnedParams = rf.set_params(**grid_search_rf.best_params_)\n",
    "rfTunnedParams.fit(X_train, y_train)\n",
    "\n",
    "y_predict=rfTunnedParams.predict(X_test)\n",
    "\n",
    "print(\"\\nRANDOM FOREST DESPRÉS DEL GREEDSEARCH:\")\n",
    "print(classification_report(y_test, y_predict,zero_division=1))\n",
    "\n",
    "training_accuracy = rfTunnedParams.score(X_train,y_train)\n",
    "testing_accuracy = rfTunnedParams.score(X_test,y_test)\n",
    "\n",
    "print('training accuracy:', training_accuracy*100)    \n",
    "print('testing accuracy:', testing_accuracy*100)\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test,y_predict, labels=rfTunnedParams.classes_), display_labels=rfTunnedParams.classes_).plot()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0b9924",
   "metadata": {},
   "source": [
    "## Resum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a01748",
   "metadata": {},
   "source": [
    "Com podem veure el model amb millors resultats és el Random Forest, amb una precisió de XXXX, un recall de XXXX i un F1 score de XXXX. \n",
    "El Grid Search ha calculat que els millors paràmetres pel Random Forest son Max_depth: XXXX, Max_features: XXXX, min_samples_leaf: XXXX, min_samples_split: XXXX i n_estimators: XXXX. \n",
    "\n",
    "Amb aquests hyperparàmetres tenim una millora del XXXX% respecte al model amb els hyperparàmetres per defecte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee71ec2",
   "metadata": {},
   "source": [
    "# **Conclusions i resum**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
