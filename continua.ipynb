{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c7dc6e88-3d56-48a1-a77e-9cabb57805a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1e5ee3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df):\n",
    "    y=df.quality\n",
    "    X=df.drop('quality',1)\n",
    "    X = min_max_scaler.fit_transform(X)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "45c4b23d-1f27-4596-9b1c-eed4d8cbd32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "#CREATE AND MERGE DATAFRAMES\n",
    "dfRed=pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "dfWhite=pd.read_csv(\"winequality-white.csv\", sep=\";\")\n",
    "\n",
    "dfRed['Type']=\"Red\"\n",
    "dfWhite['Type']=\"White\"\n",
    "df=pd.concat([dfRed,dfWhite])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "10383ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2b734f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\walli\\AppData\\Local\\Temp/ipykernel_13392/3104105429.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X=df.drop('quality',1)\n"
     ]
    }
   ],
   "source": [
    "df['Type']=labelencoder.fit_transform(df['Type'])\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "X, y = load_data(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "401c3257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6497 entries, 2587 to 2255\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         6497 non-null   float64\n",
      " 1   volatile acidity      6497 non-null   float64\n",
      " 2   citric acid           6497 non-null   float64\n",
      " 3   residual sugar        6497 non-null   float64\n",
      " 4   chlorides             6497 non-null   float64\n",
      " 5   free sulfur dioxide   6497 non-null   float64\n",
      " 6   total sulfur dioxide  6497 non-null   float64\n",
      " 7   density               6497 non-null   float64\n",
      " 8   pH                    6497 non-null   float64\n",
      " 9   sulphates             6497 non-null   float64\n",
      " 10  alcohol               6497 non-null   float64\n",
      " 11  quality               6497 non-null   int64  \n",
      " 12  Type                  6497 non-null   int32  \n",
      "dtypes: float64(11), int32(1), int64(1)\n",
      "memory usage: 685.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6d4978fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00        41\n",
      "           5       0.61      0.64      0.62       423\n",
      "           6       0.57      0.74      0.64       593\n",
      "           7       0.49      0.20      0.29       203\n",
      "           8       0.00      0.00      0.00        37\n",
      "\n",
      "    accuracy                           0.58      1300\n",
      "   macro avg       0.28      0.26      0.26      1300\n",
      "weighted avg       0.53      0.58      0.54      1300\n",
      "\n",
      "training_accuracy: 0.536078506830864\n",
      "testing_accuracy: 0.5769230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\walli\\miniconda3\\envs\\ml-environment\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\walli\\miniconda3\\envs\\ml-environment\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\walli\\miniconda3\\envs\\ml-environment\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "\n",
    "logreg = LogisticRegression(max_iter=5000)\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "y_predict = logreg.predict(X_test)\n",
    "\n",
    "# dfLogReg=pd.DataFrame()\n",
    "# dfLogReg['Real'] = y_test\n",
    "# dfLogReg['Prediction']=y_predict\n",
    "# print(dfLogReg.head())\n",
    "\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n",
    "training_accuracy = logreg.score(X_train,y_train)\n",
    "print('training_accuracy:',training_accuracy)\n",
    "\n",
    "testing_accuracy = logreg.score(X_test,y_test)\n",
    "print('testing_accuracy:',testing_accuracy)\n",
    "\n",
    "#TODO: Perqu√® dona aquells warnings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eee48c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.19      0.12      0.15        41\n",
      "           5       0.51      0.37      0.43       423\n",
      "           6       0.48      0.49      0.48       593\n",
      "           7       0.57      0.08      0.14       203\n",
      "           8       0.09      0.76      0.15        37\n",
      "\n",
      "    accuracy                           0.38      1300\n",
      "   macro avg       0.30      0.30      0.22      1300\n",
      "weighted avg       0.48      0.38      0.39      1300\n",
      "\n",
      "training_accuracy: 0.3500096209351549\n",
      "testing_accuracy: 0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\walli\\miniconda3\\envs\\ml-environment\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\walli\\miniconda3\\envs\\ml-environment\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\walli\\miniconda3\\envs\\ml-environment\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#PERCEPTRON\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "y_predict=perceptron.predict(X_test)\n",
    "\n",
    "# dfPerceptron=pd.DataFrame()\n",
    "# dfPerceptron['Real'] = y_test\n",
    "# dfPerceptron['Prediction']=y_predict\n",
    "# print(dfPerceptron.head)\n",
    "\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n",
    "training_accuracy = perceptron.score(X_train,y_train)\n",
    "print('training_accuracy:',training_accuracy)\n",
    "\n",
    "testing_accuracy = perceptron.score(X_test,y_test)\n",
    "print('testing_accuracy:',testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       1.00      0.07      0.14        41\n",
      "           5       0.71      0.72      0.72       423\n",
      "           6       0.68      0.81      0.74       593\n",
      "           7       0.73      0.53      0.61       203\n",
      "           8       1.00      0.38      0.55        37\n",
      "\n",
      "    accuracy                           0.70      1300\n",
      "   macro avg       0.69      0.42      0.46      1300\n",
      "weighted avg       0.71      0.70      0.68      1300\n",
      "\n",
      "training_accuracy: 0.9780642678468348\n",
      "testing_accuracy: 0.6984615384615385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\walli\\miniconda3\\envs\\ml-environment\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\walli\\miniconda3\\envs\\ml-environment\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\walli\\miniconda3\\envs\\ml-environment\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST\n",
    "rf = RandomForestClassifier(max_depth=14)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_predict=rf.predict(X_test)\n",
    "\n",
    "# dfRF=pd.DataFrame()\n",
    "# dfRF['Real'] = y_test\n",
    "# dfRF['Prediction']=y_predict\n",
    "# print(dfRF.head)\n",
    "\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n",
    "training_accuracy = rf.score(X_train,y_train)\n",
    "print('training_accuracy:',training_accuracy)\n",
    "\n",
    "testing_accuracy = rf.score(X_test,y_test)\n",
    "print('testing_accuracy:',testing_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
